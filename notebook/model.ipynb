{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Set the environment variable to suppress the tensorflow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Suppress the warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os.path as osp\n",
    "from typing import Any, Literal, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "\n",
    "from planner.data import AV2DataModule\n",
    "from planner.data.dataclass import Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CHECKPOINT_DIR = osp.abspath(\"../logs/train_ddp/runs/senevam_av2_radius_50\")\n",
    "DATA_DIR = osp.abspath(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = AV2DataModule(\n",
    "    batch_size=4,\n",
    "    root=osp.join(DATA_DIR, \"av2\"),\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    radius=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    "    # torch.device(\"cpu\")\n",
    ")\n",
    "dl = iter(dm.val_dataloader())\n",
    "ds = dm.val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planner.model import SeNeVAMLightningModule\n",
    "\n",
    "ckpt_dir = osp.join(CHECKPOINT_DIR, \"2025-04-05_01-57-40/checkpoints\")\n",
    "model = SeNeVAMLightningModule.load_from_checkpoint(\n",
    "    os.path.join(ckpt_dir, \"epoch_032_b2ed65b.ckpt\"),\n",
    "    map_location=device,\n",
    "    strict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(dl)\n",
    "assert isinstance(data, Scenario)\n",
    "data = data.to(device=device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    current, curr_valid = model.get_current(scenario=data, include_sdc=False)\n",
    "    target, tar_valid = model.get_target(scenario=data, include_sdc=False)\n",
    "    output = model.forward(scenario=data, horizon=60, include_sdc=False)\n",
    "print(current.shape, curr_valid.shape)\n",
    "print(target.shape, tar_valid.shape)\n",
    "print(output.y_means.shape, output.y_covars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Plot the heatmap of uncertainty\n",
    "# NOTE: this function is for single-agent heatmap plotting\n",
    "# TODO: consider about adding log-prob up or other ways to aggregate\n",
    "# multi-agent probabilities\n",
    "def plot_full_uncertainty(\n",
    "    means: npt.NDArray,\n",
    "    covars: npt.NDArray,\n",
    "    mixtures: npt.NDArray,\n",
    "    ax: Optional[plt.Axes] = None,\n",
    "    n_std: int = 1,\n",
    "    heatmap_type: Literal[\"prob\", \"log_prob\", \"logit\"] = \"log_prob\",\n",
    "    colorbar: bool = True,\n",
    "    *args: Any,\n",
    "    **kwargs: Any,\n",
    ") -> plt.Axes:\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # step 1: obtain the rectangle region covering at least 68%\n",
    "    # of the probability density function\n",
    "    minx = np.min(means[:, :, 0] - n_std * np.sqrt(covars[..., 0, 0]))\n",
    "    maxx = np.max(means[:, :, 0] + n_std * np.sqrt(covars[..., 0, 0]))\n",
    "    miny = np.min(means[:, :, 1] - n_std * np.sqrt(covars[..., 1, 1]))\n",
    "    maxy = np.max(means[:, :, 1] + n_std * np.sqrt(covars[..., 1, 1]))\n",
    "\n",
    "    probs, mask = [], []\n",
    "\n",
    "    # NOTE: efficient way to evaluate prob\n",
    "    x, y = np.linspace(minx, maxx, 100), np.linspace(miny, maxy, 100)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    points = np.vstack((x.ravel(), y.ravel())).T  # shape (10000, 2)\n",
    "\n",
    "    for mean, covar, pi in zip(means, covars, mixtures):\n",
    "        # calculate the Gaussian probability density function\n",
    "        inv_covar = np.linalg.inv(covar)  # shape (T, 2, 2)\n",
    "        det_covar = np.linalg.det(covar)  # shape (T,)\n",
    "        diff = points[:, None, ...] - mean[None, ...]  # shape (10000, T, 2)\n",
    "        mahalanobis = np.einsum(\"btj, tij, bti -> bt\", diff, inv_covar, diff)\n",
    "        log_prob = -0.5 * (\n",
    "            mahalanobis + np.log(det_covar + 1e-10) + 2 * np.log(2 * np.pi)\n",
    "        )\n",
    "        log_prob += np.log(pi + 1e-10)\n",
    "        probs.append(np.exp(log_prob))\n",
    "\n",
    "        # TODO: aggregate the probabilities from multiple agents?\n",
    "\n",
    "        # NOTE: filter out outliers\n",
    "        mask.append(\n",
    "            np.reshape(\n",
    "                np.all(mahalanobis > n_std * math.sqrt(2), -1),\n",
    "                (100, 100),\n",
    "            ).astype(bool)\n",
    "        )\n",
    "    mask = np.all(mask, axis=0)\n",
    "\n",
    "    probs = np.stack(probs, axis=0)\n",
    "    probs = np.mean(np.sum(probs, axis=0), axis=-1)\n",
    "    probs = np.reshape(probs, shape=(100, 100))\n",
    "    probs = np.ma.masked_where(mask, probs)\n",
    "    if heatmap_type == \"log_prob\":\n",
    "        probs = np.log(probs + 1e-10)\n",
    "        heatmap_name = \"Log-Probability\"\n",
    "    elif heatmap_type == \"logit\":\n",
    "        probs = np.log((probs + 1e-10) / (1 - probs - 1e-10))\n",
    "        heatmap_name = \"Logit\"\n",
    "    else:\n",
    "        heatmap_name = \"Probability\"\n",
    "    cbar = ax.contourf(x, y, probs, *args, **kwargs)\n",
    "\n",
    "    if colorbar:\n",
    "        if len(ax.get_figure().axes) < 2:\n",
    "            cbar = ax.get_figure().colorbar(cbar, ax=ax)\n",
    "            cbar.ax.set_ylabel(\n",
    "                heatmap_name + \" to be visited\",\n",
    "                rotation=90,\n",
    "                labelpad=5,\n",
    "                fontdict={\"color\": \"white\"},\n",
    "            )\n",
    "            cbar.ax.set_yticklabels(\n",
    "                cbar.ax.get_yticklabels(), fontdict={\"color\": \"white\"}\n",
    "            )\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from planner.data.viz import plot_scenario\n",
    "\n",
    "BATCH_INDEX = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# plot the scenario\n",
    "ax = plot_scenario(\n",
    "    scenario=data[BATCH_INDEX].to(\"cpu\"), ax=ax, crop_to_bounds=False\n",
    ")\n",
    "scenario_id = data[BATCH_INDEX].scenario_id.decode(\"utf-8\")\n",
    "map_api = ds.get_map_api(scenario_id=scenario_id)\n",
    "for _, area in map_api.vector_drivable_areas.items():\n",
    "    ax.fill(area.xyz[..., 0], area.xyz[..., 1], color=\"#5E5E5D\", zorder=0)\n",
    "\n",
    "# plot the ground-truth observations\n",
    "cum_target = target.cumsum(dim=-2) + current\n",
    "for tar, val in zip(cum_target[BATCH_INDEX], tar_valid[BATCH_INDEX]):\n",
    "    tar = tar[val]\n",
    "    ax.plot(\n",
    "        tar[..., 0].cpu().numpy(),\n",
    "        tar[..., 1].cpu().numpy(),\n",
    "        \"g-\",\n",
    "        lw=2,\n",
    "        alpha=0.75,\n",
    "        zorder=20,\n",
    "    )\n",
    "\n",
    "# plot the predictions\n",
    "cum_y_means = output.y_means.cumsum(dim=-2) + current.unsqueeze(-3)\n",
    "cum_y_covars = output.y_covars.cumsum(dim=-3)\n",
    "for y_means, val in zip(cum_y_means[BATCH_INDEX], tar_valid[BATCH_INDEX]):\n",
    "    for y_mean in y_means:\n",
    "        xy = y_mean[val][..., 0:2].cpu().numpy()\n",
    "        ax.plot(\n",
    "            xy[..., 0],\n",
    "            xy[..., 1],\n",
    "            \"r--\",\n",
    "            lw=2,\n",
    "            alpha=0.5,\n",
    "            zorder=15,\n",
    "        )\n",
    "\n",
    "ax = plot_full_uncertainty(\n",
    "    means=cum_y_means[BATCH_INDEX, 0, ..., 0:2].cpu().numpy(),\n",
    "    covars=cum_y_covars[BATCH_INDEX, 0, ..., 0:2, 0:2].cpu().numpy(),\n",
    "    mixtures=np.ones(6) / 6,\n",
    "    ax=ax,\n",
    "    n_std=1,\n",
    "    heatmap_type=\"log_prob\",\n",
    "    alpha=0.75,\n",
    "    zorder=15,\n",
    ")\n",
    "fig.set_facecolor(\"#000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from planner.model.function.eval import MinADE\n",
    "\n",
    "min_ade = MinADE().to(device=device)\n",
    "min_ade(\n",
    "    input_xy=cum_y_means[:, ..., 0:2],\n",
    "    target_xy=cum_target.unsqueeze(-3)[:, ..., 0:2],\n",
    "    valid=tar_valid.unsqueeze(-2)[:],\n",
    ")\n",
    "min_ade.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
